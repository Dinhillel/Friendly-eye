Assistive Vision System for Visually Impaired Users

 Project Overview
This project is an intelligent assistive technology solution designed to help visually impaired users interact with their environment through real-time computer vision and natural language processing. The system combines multiple AI components to provide seamless voice-based interaction with the visual world.
Core Functionality
The system enables users to ask natural language questions about their surroundings and receive spoken responses. For example:

User: "What is in front of me?"
System: "There is a red chair and a table in front of you."

âœ¨ Features

ğŸ” Computer Vision
Real-time Object Detection: Uses YOLOv8 for accurate object recognition
Multi-dataset Training: Trained on COCO and VizWiz VQA datasets
Live Camera Feed: Processes video stream in real-time
Confidence Scoring: Provides detection confidence levels

ğŸ™ï¸ Audio Processing
Speech-to-Text: Whisper-based voice command recognition
Text-to-Speech: Natural voice feedback with pyttsx3
Multi-language Support: Configurable language settings
Voice Commands: Interactive voice-controlled interface

ğŸ§  Natural Language Processing
Question Answering: T5-based contextual understanding
Scene Description: Intelligent interpretation of visual context
Conversational Interface: Natural language interaction

âš¡ Performance

Real-time Processing: 30 FPS camera processing
GPU Acceleration: CUDA support for faster inference
Optimized Models: Lightweight models for efficient processing

 System Architecture
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Camera Input  â”‚â”€â”€â”€â–¶â”‚ YOLO Detector   â”‚â”€â”€â”€â–¶â”‚ Object Context  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â–¼
â”‚  Voice Output   â”‚â—€â”€â”€â”€â”‚   T5 Responder  â”‚â—€â”€â”€â”€â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Scene Analysis  â”‚
        â–²                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                              â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   TTS Engine    â”‚â—€â”€â”€â”€â”‚ Voice Question  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                        â–²
        â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Speaker      â”‚    â”‚ STT (Whisper)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–²
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Microphone      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

VISION_MODEL/
â”œâ”€â”€ app/

â”œâ”€â”€ config.py        # Configuration settings

â”œâ”€â”€ main.py          # Main application entry point
â”‚ 
â””â”€â”€ pipeline.py      # Main processing pipeline
â”œâ”€â”€ vision/
â”‚   â”œâ”€â”€ opencv.py        # OpenCV camera utilities
â”‚   â””â”€â”€ yolo_detector.py # YOLO object detection module
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ stt.py          # Speech-to-Text processing
â”‚   â””â”€â”€ tts.py          # Text-to-Speech synthesis
â”œâ”€â”€ nlp/
â”‚   â””â”€â”€ t5model.py      # T5 question-answering model
â”œâ”€â”€ Dataset_vizwiz/     # VizWiz dataset (excluded from git)
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”œâ”€â”€ download_vizwiz.py  # Dataset download script
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file

 Clone the Repository:
git clone https://github.com/DinHillel/Eye-Frindly.git
cd Frindly-Eye
                       

